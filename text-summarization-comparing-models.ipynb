{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-04T06:36:28.191229Z","iopub.status.busy":"2024-02-04T06:36:28.190424Z","iopub.status.idle":"2024-02-04T06:36:28.740491Z","shell.execute_reply":"2024-02-04T06:36:28.739369Z","shell.execute_reply.started":"2024-02-04T06:36:28.191165Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:36:28.744071Z","iopub.status.busy":"2024-02-04T06:36:28.743071Z","iopub.status.idle":"2024-02-04T06:36:29.442815Z","shell.execute_reply":"2024-02-04T06:36:29.441500Z","shell.execute_reply.started":"2024-02-04T06:36:28.744004Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:36:29.444874Z","iopub.status.busy":"2024-02-04T06:36:29.444352Z","iopub.status.idle":"2024-02-04T06:36:45.161284Z","shell.execute_reply":"2024-02-04T06:36:45.159686Z","shell.execute_reply.started":"2024-02-04T06:36:29.444838Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\n","Requirement already satisfied: rouge-score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n","Requirement already satisfied: bert-score in /opt/conda/lib/python3.10/site-packages (0.3.13)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.24.4)\n","Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.1.2+cpu)\n","Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.2.0)\n","Requirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.37.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.31.0)\n","Requirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.66.1)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.4)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert-score) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert-score) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2023.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.20.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.47.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (9.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n"]}],"source":["!pip install nltk rouge-score bert-score"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:36:45.166356Z","iopub.status.busy":"2024-02-04T06:36:45.165801Z","iopub.status.idle":"2024-02-04T06:36:50.033810Z","shell.execute_reply":"2024-02-04T06:36:50.032390Z","shell.execute_reply.started":"2024-02-04T06:36:45.166303Z"},"trusted":true},"outputs":[],"source":["import nltk\n","from datasets import load_dataset\n","from nltk.translate.bleu_score import corpus_bleu\n","from rouge_score import rouge_scorer\n","from bert_score import score"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:36:50.035959Z","iopub.status.busy":"2024-02-04T06:36:50.035254Z","iopub.status.idle":"2024-02-04T06:36:50.042255Z","shell.execute_reply":"2024-02-04T06:36:50.040689Z","shell.execute_reply.started":"2024-02-04T06:36:50.035922Z"},"trusted":true},"outputs":[],"source":["import warnings\n","\n","# Suppress the warning\n","warnings.filterwarnings(\"ignore\", message=\"Your max_length is set to *\")"]},{"cell_type":"markdown","metadata":{},"source":["## Reading the Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:36:50.044714Z","iopub.status.busy":"2024-02-04T06:36:50.044191Z","iopub.status.idle":"2024-02-04T06:37:05.488248Z","shell.execute_reply":"2024-02-04T06:37:05.486515Z","shell.execute_reply.started":"2024-02-04T06:36:50.044673Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: py7zr in /opt/conda/lib/python3.10/site-packages (0.20.8)\n","Requirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\n","Requirement already satisfied: pycryptodomex>=3.16.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (3.20.0)\n","Requirement already satisfied: pyzstd>=0.15.9 in /opt/conda/lib/python3.10/site-packages (from py7zr) (0.15.9)\n","Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.0)\n","Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.0.2)\n","Requirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from py7zr) (0.2.3)\n","Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.0.0)\n","Requirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.0)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install py7zr"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:05.493072Z","iopub.status.busy":"2024-02-04T06:37:05.491828Z","iopub.status.idle":"2024-02-04T06:37:06.360596Z","shell.execute_reply":"2024-02-04T06:37:06.359567Z","shell.execute_reply.started":"2024-02-04T06:37:05.493020Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f87958dfc66c43f9853f11a3387a28d2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = load_dataset(\"samsum\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:06.362800Z","iopub.status.busy":"2024-02-04T06:37:06.362177Z","iopub.status.idle":"2024-02-04T06:37:06.372737Z","shell.execute_reply":"2024-02-04T06:37:06.371227Z","shell.execute_reply.started":"2024-02-04T06:37:06.362768Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 14732\n","    })\n","    test: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 819\n","    })\n","    validation: Dataset({\n","        features: ['id', 'dialogue', 'summary'],\n","        num_rows: 818\n","    })\n","})"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:06.374952Z","iopub.status.busy":"2024-02-04T06:37:06.374619Z","iopub.status.idle":"2024-02-04T06:37:06.395214Z","shell.execute_reply":"2024-02-04T06:37:06.394132Z","shell.execute_reply.started":"2024-02-04T06:37:06.374925Z"},"trusted":true},"outputs":[],"source":["df= dataset['test'].to_pandas()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:06.400675Z","iopub.status.busy":"2024-02-04T06:37:06.399878Z","iopub.status.idle":"2024-02-04T06:37:06.408456Z","shell.execute_reply":"2024-02-04T06:37:06.407569Z","shell.execute_reply.started":"2024-02-04T06:37:06.400630Z"},"trusted":true},"outputs":[],"source":["df= df.sample(n= 150, replace= False).reset_index(drop= True)  "]},{"cell_type":"markdown","metadata":{},"source":["## Analysing the dataset"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:06.410573Z","iopub.status.busy":"2024-02-04T06:37:06.409702Z","iopub.status.idle":"2024-02-04T06:37:06.431295Z","shell.execute_reply":"2024-02-04T06:37:06.430299Z","shell.execute_reply.started":"2024-02-04T06:37:06.410539Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>dialogue</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>13816051</td>\n","      <td>Harriette: Have you ever gone ghost hunting? ;...</td>\n","      <td>Jamie has never gone ghost hunting but Harriet...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>13681603</td>\n","      <td>Ella: so? \\r\\nMolly: ?\\r\\nElla: come on! pics ...</td>\n","      <td>Chuck told Ella that he'd met up with Molly. H...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13729101</td>\n","      <td>Brenda: Hello, is this Sandra Donovan?\\r\\nSand...</td>\n","      <td>Sandra and Brenda used to work together in the...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13863098</td>\n","      <td>Cristina: Hey\\nCristina: Do you think we can m...</td>\n","      <td>Gaya and Cristina are going to meet at Gaya's ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>13681441</td>\n","      <td>Joanna: They are sending emails about Lewandow...</td>\n","      <td>Lewandowska has measles. There are vaccination...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                                           dialogue  \\\n","0  13816051  Harriette: Have you ever gone ghost hunting? ;...   \n","1  13681603  Ella: so? \\r\\nMolly: ?\\r\\nElla: come on! pics ...   \n","2  13729101  Brenda: Hello, is this Sandra Donovan?\\r\\nSand...   \n","3  13863098  Cristina: Hey\\nCristina: Do you think we can m...   \n","4  13681441  Joanna: They are sending emails about Lewandow...   \n","\n","                                             summary  \n","0  Jamie has never gone ghost hunting but Harriet...  \n","1  Chuck told Ella that he'd met up with Molly. H...  \n","2  Sandra and Brenda used to work together in the...  \n","3  Gaya and Cristina are going to meet at Gaya's ...  \n","4  Lewandowska has measles. There are vaccination...  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:06.433149Z","iopub.status.busy":"2024-02-04T06:37:06.432653Z","iopub.status.idle":"2024-02-04T06:37:06.445997Z","shell.execute_reply":"2024-02-04T06:37:06.444874Z","shell.execute_reply.started":"2024-02-04T06:37:06.433120Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 150 entries, 0 to 149\n","Data columns (total 3 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   id        150 non-null    object\n"," 1   dialogue  150 non-null    object\n"," 2   summary   150 non-null    object\n","dtypes: object(3)\n","memory usage: 3.6+ KB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:06.448180Z","iopub.status.busy":"2024-02-04T06:37:06.447389Z","iopub.status.idle":"2024-02-04T06:37:06.466622Z","shell.execute_reply":"2024-02-04T06:37:06.465321Z","shell.execute_reply.started":"2024-02-04T06:37:06.448149Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>dialogue</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>150</td>\n","      <td>150</td>\n","      <td>150</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>150</td>\n","      <td>150</td>\n","      <td>150</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>13816051</td>\n","      <td>Harriette: Have you ever gone ghost hunting? ;...</td>\n","      <td>Jamie has never gone ghost hunting but Harriet...</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              id                                           dialogue  \\\n","count        150                                                150   \n","unique       150                                                150   \n","top     13816051  Harriette: Have you ever gone ghost hunting? ;...   \n","freq           1                                                  1   \n","\n","                                                  summary  \n","count                                                 150  \n","unique                                                150  \n","top     Jamie has never gone ghost hunting but Harriet...  \n","freq                                                    1  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df.describe()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:06.468389Z","iopub.status.busy":"2024-02-04T06:37:06.468019Z","iopub.status.idle":"2024-02-04T06:37:06.474800Z","shell.execute_reply":"2024-02-04T06:37:06.473599Z","shell.execute_reply.started":"2024-02-04T06:37:06.468359Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dialogue:\n"," Harriette: Have you ever gone ghost hunting? ;o\n","Jamie: Ghost hunting? Nah, not really... Have you?\n","Harriette: Yeah, once when I was in high school! There was a run-down building in the neighbourhood and we went to investigate it with my friends\n","Jamie: How was it? Did you find something?\n","Harriette: We didn't see any ghosts, haha\n","Harriette: But let me tell you that I never thought I'd freak out this much at hearing a cat meow\n","Harriette: There's just something about the atmosphere... that makes you overreact and find normal but unexpected things really creepy\n","Jamie: I guess that's part of the experience? :p\n","Harriette: Yeah, if I could choose again, I'd probably still decide to go - I don't regret it! But I definitely wouldn't try something like that alone ^^;\n","\n","Summary:\n"," Jamie has never gone ghost hunting but Harriette did with her friends once in high school. They did not see any ghosts and she only got frightened by a cat's miaowing.\n"]}],"source":["print('Dialogue:\\n',df['dialogue'][0])\n","print('\\nSummary:\\n',df['summary'][0])"]},{"cell_type":"markdown","metadata":{},"source":["## Model Metric Evaluation"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:06.477422Z","iopub.status.busy":"2024-02-04T06:37:06.476646Z","iopub.status.idle":"2024-02-04T06:37:06.486856Z","shell.execute_reply":"2024-02-04T06:37:06.485632Z","shell.execute_reply.started":"2024-02-04T06:37:06.477368Z"},"trusted":true},"outputs":[],"source":["def calculate_redundancy(summaries):\n","    \n","    total_tokens = sum(len(summary.split()) for summary in summaries)\n","    unique_tokens = len(set(token for summary in summaries for token in summary.split()))\n","    redundancy_score = 1 - (unique_tokens / total_tokens)\n","    \n","    return redundancy_score"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:06.489258Z","iopub.status.busy":"2024-02-04T06:37:06.488856Z","iopub.status.idle":"2024-02-04T06:37:06.505042Z","shell.execute_reply":"2024-02-04T06:37:06.503792Z","shell.execute_reply.started":"2024-02-04T06:37:06.489227Z"},"trusted":true},"outputs":[],"source":["def calc_metrics(actual_summaries, pred_summaries):\n","    \n","    # Calculate BLEU Score\n","    actual_summaries_tokenized = [[ref.split()] for ref in actual_summaries]         # tokenizing the actual summary\n","    pred_summaries_tokenized = [output.split() for output in pred_summaries]         # tokenizing the predicted summary\n","    bleu_score = corpus_bleu(actual_summaries_tokenized, pred_summaries_tokenized)   # comparing the tokens to calculate BLEU score\n","    \n","    \n","    # Calculate BERT Score\n","    P, R, F1 = score(actual_summaries, pred_summaries, lang='en', verbose=False)     # returns Precision, Recall and F1 score\n","    bert_score = F1.mean().item()                                                    # takes the mean of F1 scores across all examples (.item() used to convert PyTorch tensor into scalar value) \n","    \n","    \n","    # Calculate ROUGE Scores\n","    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)          # creates an object 'rouge' that will be used to compute ROUGE scores with ROUGE-1, ROUGE-2, and ROUGE-L metrics, using stemming\n","             \n","    rouge_1_scores = []\n","    rouge_2_scores = []\n","    rouge_L_scores = []\n","    for pred, actual in zip(pred_summaries, actual_summaries):\n","        rouge_scores = rouge.score(pred, actual)                                                # returns a dictionary of mentioned ROUGE scores each of which contain precison, recall and F1 score\n","        rouge_1_scores.append(rouge_scores['rouge1'].fmeasure)\n","        rouge_2_scores.append(rouge_scores['rouge2'].fmeasure)\n","        rouge_L_scores.append(rouge_scores['rougeL'].fmeasure)\n","    \n","    rouge_1_f1 = sum(rouge_1_scores) / len(rouge_1_scores)                                      # calculating the average rouge scores (considering F1 score)\n","    rouge_2_f1 = sum(rouge_2_scores) / len(rouge_2_scores)\n","    rouge_L_f1 = sum(rouge_L_scores) / len(rouge_L_scores)\n","    \n","    # Calculate Redundancy Score\n","    redundancy_score = calculate_redundancy(pred_summaries)\n","    \n","    \n","    return bleu_score, bert_score, rouge_1_f1, rouge_2_f1, rouge_L_f1, redundancy_score        # returning all the calculated metrics"]},{"cell_type":"markdown","metadata":{},"source":["## Testing on different models"]},{"cell_type":"markdown","metadata":{},"source":["##### 1. facebook/bart-large-cnn"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:06.506997Z","iopub.status.busy":"2024-02-04T06:37:06.506585Z","iopub.status.idle":"2024-02-04T06:37:25.014001Z","shell.execute_reply":"2024-02-04T06:37:25.013085Z","shell.execute_reply.started":"2024-02-04T06:37:06.506967Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-04 06:37:07.022931: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-04 06:37:07.023046: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-04 06:37:07.026859: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"text/plain":["[{'summary_text': \"Harriette went ghost hunting with her friends when she was in high school. They investigated a run-down building in the neighbourhood and didn't see any ghosts. Harriette says she doesn't regret going ghost hunting, but she wouldn't do it alone.\"}]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import pipeline\n","summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n","summarizer(df['dialogue'][0], max_length= 130, min_length=30, truncation= True)   "]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:25.016825Z","iopub.status.busy":"2024-02-04T06:37:25.015467Z","iopub.status.idle":"2024-02-04T06:37:30.589411Z","shell.execute_reply":"2024-02-04T06:37:30.588180Z","shell.execute_reply.started":"2024-02-04T06:37:25.016788Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Harriette went ghost hunting with her friends when she was in high school. They investigated a run-down building in the neighbourhood.'"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["summarizer(df['dialogue'][0], max_length= 30, min_length=10, truncation= True)[0]['summary_text']"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:37:30.591375Z","iopub.status.busy":"2024-02-04T06:37:30.590973Z","iopub.status.idle":"2024-02-04T06:49:49.889648Z","shell.execute_reply":"2024-02-04T06:49:49.888335Z","shell.execute_reply.started":"2024-02-04T06:37:30.591342Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Your max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n","Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","Your max_length is set to 30, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n","Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"]}],"source":["predictions= []\n","for i in range(0,len(df)):\n","    pred= summarizer(df['dialogue'][i], max_length=30, min_length=10, truncation= True)[0]['summary_text']\n","    predictions.append(pred)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:49:49.891750Z","iopub.status.busy":"2024-02-04T06:49:49.891405Z","iopub.status.idle":"2024-02-04T06:50:38.273898Z","shell.execute_reply":"2024-02-04T06:50:38.272547Z","shell.execute_reply.started":"2024-02-04T06:49:49.891722Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["BLEU,BERT,Rouge_1,Rouge_2,Rouge_L,Redundancy = calc_metrics(df['summary'].tolist(), predictions)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:50:38.276218Z","iopub.status.busy":"2024-02-04T06:50:38.275833Z","iopub.status.idle":"2024-02-04T06:50:38.285159Z","shell.execute_reply":"2024-02-04T06:50:38.283871Z","shell.execute_reply.started":"2024-02-04T06:50:38.276186Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BLEU Score:  0.06819376766320177\n","BERT Score:  0.8777881860733032\n","Rouge-1 Score:  0.3537191342343953\n","Rouge-2 Score:  0.11681459839731756\n","Rouge-L Score:  0.2743427144308629\n","Redundancy Score:  0.5372358850017319\n"]}],"source":["BLEU_scores= []\n","BERT_scores= []\n","Rouge_1_scores= []\n","Rouge_2_scores= []\n","Rouge_L_scores= []\n","Redundancy_scores= []\n","print('BLEU Score: ',BLEU)\n","print('BERT Score: ',BERT)\n","print('Rouge-1 Score: ',Rouge_1)\n","print('Rouge-2 Score: ',Rouge_2)\n","print('Rouge-L Score: ',Rouge_L)\n","print('Redundancy Score: ',Redundancy)\n","BLEU_scores.append(BLEU)\n","BERT_scores.append(BERT)\n","Rouge_1_scores.append(Rouge_1)\n","Rouge_2_scores.append(Rouge_2)\n","Rouge_L_scores.append(Rouge_L)\n","Redundancy_scores.append(Redundancy)"]},{"cell_type":"markdown","metadata":{},"source":["#### 2. sshleifer/distilbart-cnn-12-6"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:50:38.287772Z","iopub.status.busy":"2024-02-04T06:50:38.287009Z","iopub.status.idle":"2024-02-04T06:50:52.937536Z","shell.execute_reply":"2024-02-04T06:50:52.936205Z","shell.execute_reply.started":"2024-02-04T06:50:38.287737Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf5c0061817149899698f55cfa67dfd9","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08f23945b17b491fa0d4b13246339de2","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75b9b61c4edd4674b1f916096e973739","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8fc1c6b2b4344f793834821fd925d34","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"831eee86432241c989f0875a3101d2c8","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["' Harriette: Have you ever gone ghost hunting? ;o\\xa0\\xa0 Jamie: Ghost hunting? Nah, not really... Have you?'"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["pipe = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n","pipe(df['dialogue'][0], max_length= 30, min_length=10, truncation= True)[0]['summary_text']       \n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:50:52.940186Z","iopub.status.busy":"2024-02-04T06:50:52.939380Z","iopub.status.idle":"2024-02-04T06:58:56.717640Z","shell.execute_reply":"2024-02-04T06:58:56.716192Z","shell.execute_reply.started":"2024-02-04T06:50:52.940135Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Your max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n","Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","Your max_length is set to 30, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n","Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"]}],"source":["predictions= []\n","for i in range(0,len(df)):\n","    pred= pipe(df['dialogue'][i], max_length=30, min_length=10, truncation= True)[0]['summary_text']\n","    predictions.append(pred)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:58:56.720290Z","iopub.status.busy":"2024-02-04T06:58:56.719785Z","iopub.status.idle":"2024-02-04T06:59:45.383501Z","shell.execute_reply":"2024-02-04T06:59:45.382157Z","shell.execute_reply.started":"2024-02-04T06:58:56.720227Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["BLEU,BERT,Rouge_1,Rouge_2,Rouge_L,Redundancy = calc_metrics(df['summary'].tolist(), predictions)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:59:45.387537Z","iopub.status.busy":"2024-02-04T06:59:45.386295Z","iopub.status.idle":"2024-02-04T06:59:45.395723Z","shell.execute_reply":"2024-02-04T06:59:45.394313Z","shell.execute_reply.started":"2024-02-04T06:59:45.387487Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BLEU Score:  0.04917266108914351\n","BERT Score:  0.8652205467224121\n","Rouge-1 Score:  0.31109114879000405\n","Rouge-2 Score:  0.09968754622698285\n","Rouge-L Score:  0.24437495396197187\n","Redundancy Score:  0.539986559139785\n"]}],"source":["print('BLEU Score: ',BLEU)\n","print('BERT Score: ',BERT)\n","print('Rouge-1 Score: ',Rouge_1)\n","print('Rouge-2 Score: ',Rouge_2)\n","print('Rouge-L Score: ',Rouge_L)\n","print('Redundancy Score: ',Redundancy)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:59:45.397726Z","iopub.status.busy":"2024-02-04T06:59:45.397285Z","iopub.status.idle":"2024-02-04T06:59:45.406871Z","shell.execute_reply":"2024-02-04T06:59:45.405852Z","shell.execute_reply.started":"2024-02-04T06:59:45.397693Z"},"trusted":true},"outputs":[],"source":["BLEU_scores.append(BLEU)\n","BERT_scores.append(BERT)\n","Rouge_1_scores.append(Rouge_1)\n","Rouge_2_scores.append(Rouge_2)\n","Rouge_L_scores.append(Rouge_L)\n","Redundancy_scores.append(Redundancy)"]},{"cell_type":"markdown","metadata":{},"source":["#### 3. philschmid/bart-large-cnn-samsum"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T06:59:45.408633Z","iopub.status.busy":"2024-02-04T06:59:45.408195Z","iopub.status.idle":"2024-02-04T07:00:02.029332Z","shell.execute_reply":"2024-02-04T07:00:02.027991Z","shell.execute_reply.started":"2024-02-04T06:59:45.408602Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c69f7abb4d1142999f0af99e05967327","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c26668f70494d34a9ffe1335401f758","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"372ef2923c16420c859b668225a4356a","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/300 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33d7153339c84f7ba2091a0a5fda1fbc","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91814a78991040d7b7594052becaea5e","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b70dfd8a121444b2a06c933094a6cc52","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[{'summary_text': 'Harriette went ghost hunting once when she was in high school with her friends in a run-down building in the neighbourhood'}]\n"]}],"source":["pipe = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")\n","print(pipe(df['dialogue'][0], max_length= 30, min_length=10, truncation= True)) \n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:00:02.038232Z","iopub.status.busy":"2024-02-04T07:00:02.037398Z","iopub.status.idle":"2024-02-04T07:11:01.837570Z","shell.execute_reply":"2024-02-04T07:11:01.836297Z","shell.execute_reply.started":"2024-02-04T07:00:02.038191Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Your max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n","Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","Your max_length is set to 30, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n","Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"]}],"source":["predictions= []\n","for i in range(0,len(df)):\n","    pred= pipe(df['dialogue'][i], max_length=30, min_length=10, truncation= True)[0]['summary_text']\n","    predictions.append(pred)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:11:01.839600Z","iopub.status.busy":"2024-02-04T07:11:01.839196Z","iopub.status.idle":"2024-02-04T07:11:47.369004Z","shell.execute_reply":"2024-02-04T07:11:47.366542Z","shell.execute_reply.started":"2024-02-04T07:11:01.839569Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["BLEU,BERT,Rouge_1,Rouge_2,Rouge_L,Redundancy = calc_metrics(df['summary'].tolist(), predictions)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:11:47.371323Z","iopub.status.busy":"2024-02-04T07:11:47.370882Z","iopub.status.idle":"2024-02-04T07:11:47.383484Z","shell.execute_reply":"2024-02-04T07:11:47.381988Z","shell.execute_reply.started":"2024-02-04T07:11:47.371291Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BLEU Score:  0.1716887652393266\n","BERT Score:  0.9205511212348938\n","Rouge-1 Score:  0.5321249492047778\n","Rouge-2 Score:  0.2916850985556861\n","Rouge-L Score:  0.44859674661969223\n","Redundancy Score:  0.5589910496338486\n"]}],"source":["print('BLEU Score: ',BLEU)\n","print('BERT Score: ',BERT)\n","print('Rouge-1 Score: ',Rouge_1)\n","print('Rouge-2 Score: ',Rouge_2)\n","print('Rouge-L Score: ',Rouge_L)\n","print('Redundancy Score: ',Redundancy)\n","BLEU_scores.append(BLEU)\n","BERT_scores.append(BERT)\n","Rouge_1_scores.append(Rouge_1)\n","Rouge_2_scores.append(Rouge_2)\n","Rouge_L_scores.append(Rouge_L)\n","Redundancy_scores.append(Redundancy)"]},{"cell_type":"markdown","metadata":{},"source":["#### 4. google/pegasus-cnn_dailymail"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:11:47.385796Z","iopub.status.busy":"2024-02-04T07:11:47.385320Z","iopub.status.idle":"2024-02-04T07:12:41.463289Z","shell.execute_reply":"2024-02-04T07:12:41.462004Z","shell.execute_reply.started":"2024-02-04T07:11:47.385752Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c98ba65049c46009de0d9547ffa5cbe","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02640d127977479086d249cd40357138","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"273a377b296540d7b84c46b02012d18a","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36e0d1ce26d148e3bed4d250b3a76b88","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13f5a63fc4064a7a9adc52df3aa49b9a","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4be493d86f9e482887a658ffabbaa211","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["\"Harriette went ghost hunting with her friends in high school .<n>She never thought she'd freak out at hearing a cat meow \""]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n","pipe(df['dialogue'][0], max_length= 30, min_length=10, truncation= True)[0]['summary_text'] "]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:12:41.465477Z","iopub.status.busy":"2024-02-04T07:12:41.465027Z","iopub.status.idle":"2024-02-04T07:34:06.451517Z","shell.execute_reply":"2024-02-04T07:34:06.450184Z","shell.execute_reply.started":"2024-02-04T07:12:41.465443Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Your max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n","Your max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n","Your max_length is set to 30, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n","Your max_length is set to 30, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n","Your max_length is set to 30, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n","Your max_length is set to 30, but your input_length is only 18. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n","Your max_length is set to 30, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n","Your max_length is set to 30, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"]}],"source":["predictions= []\n","for i in range(0,len(df)):\n","    pred= pipe(df['dialogue'][i], max_length=30, min_length=10, truncation= True)[0]['summary_text']\n","    predictions.append(pred)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:34:06.454815Z","iopub.status.busy":"2024-02-04T07:34:06.453512Z","iopub.status.idle":"2024-02-04T07:34:59.116288Z","shell.execute_reply":"2024-02-04T07:34:59.114958Z","shell.execute_reply.started":"2024-02-04T07:34:06.454769Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["BLEU,BERT,Rouge_1,Rouge_2,Rouge_L,Redundancy = calc_metrics(df['summary'].tolist(), predictions)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:34:59.118707Z","iopub.status.busy":"2024-02-04T07:34:59.118229Z","iopub.status.idle":"2024-02-04T07:34:59.126506Z","shell.execute_reply":"2024-02-04T07:34:59.125336Z","shell.execute_reply.started":"2024-02-04T07:34:59.118663Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BLEU Score:  0.050751401318902996\n","BERT Score:  0.8598005175590515\n","Rouge-1 Score:  0.31919036232745535\n","Rouge-2 Score:  0.09517286377370723\n","Rouge-L Score:  0.2538947214047014\n","Redundancy Score:  0.5382047477744807\n"]}],"source":["print('BLEU Score: ',BLEU)\n","print('BERT Score: ',BERT)\n","print('Rouge-1 Score: ',Rouge_1)\n","print('Rouge-2 Score: ',Rouge_2)\n","print('Rouge-L Score: ',Rouge_L)\n","print('Redundancy Score: ',Redundancy)\n","BLEU_scores.append(BLEU)\n","BERT_scores.append(BERT)\n","Rouge_1_scores.append(Rouge_1)\n","Rouge_2_scores.append(Rouge_2)\n","Rouge_L_scores.append(Rouge_L)\n","Redundancy_scores.append(Redundancy)"]},{"cell_type":"markdown","metadata":{},"source":["#### 5. knkarthick/MEETING_SUMMARY"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:34:59.128954Z","iopub.status.busy":"2024-02-04T07:34:59.128505Z","iopub.status.idle":"2024-02-04T07:35:22.623954Z","shell.execute_reply":"2024-02-04T07:35:22.615039Z","shell.execute_reply.started":"2024-02-04T07:34:59.128913Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76ec8bfb20934c84a5711c972e873555","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23a07e7bb2ec4988998613559fcffd00","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a30cf6fbb464c89b3fe754cb00c517d","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/337 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6166bd406ea64a28babb061157b91515","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a3862379b3b407eb51c116f814689d3","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b39cdf057bf4407a86c2e53f373e6d8","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b59cb9cc0624ab3a6a609ac3435c0d5","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["\"Harriette went ghost hunting once when she was in high school. She didn't find any ghosts but she did find it\""]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["pipe = pipeline(\"summarization\", model=\"knkarthick/MEETING_SUMMARY\")\n","pipe(df['dialogue'][0], max_length= 30, min_length=10, truncation= True)[0]['summary_text'] "]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:35:22.637049Z","iopub.status.busy":"2024-02-04T07:35:22.631305Z","iopub.status.idle":"2024-02-04T07:47:52.571816Z","shell.execute_reply":"2024-02-04T07:47:52.570642Z","shell.execute_reply.started":"2024-02-04T07:35:22.636813Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Your max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n","Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","Your max_length is set to 30, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n","Your max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"]}],"source":["predictions= []\n","for i in range(0,len(df)):\n","    pred= pipe(df['dialogue'][i], max_length=30, min_length=10, truncation= True)[0]['summary_text']\n","    predictions.append(pred)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:47:52.574112Z","iopub.status.busy":"2024-02-04T07:47:52.573762Z","iopub.status.idle":"2024-02-04T07:48:38.052839Z","shell.execute_reply":"2024-02-04T07:48:38.051354Z","shell.execute_reply.started":"2024-02-04T07:47:52.574083Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["BLEU,BERT,Rouge_1,Rouge_2,Rouge_L,Redundancy = calc_metrics(df['summary'].tolist(), predictions)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:48:38.055120Z","iopub.status.busy":"2024-02-04T07:48:38.054613Z","iopub.status.idle":"2024-02-04T07:48:38.063786Z","shell.execute_reply":"2024-02-04T07:48:38.062800Z","shell.execute_reply.started":"2024-02-04T07:48:38.055072Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BLEU Score:  0.16257379211637224\n","BERT Score:  0.9168060421943665\n","Rouge-1 Score:  0.5114647009961298\n","Rouge-2 Score:  0.2738689357642878\n","Rouge-L Score:  0.43198515492010814\n","Redundancy Score:  0.5599679101484156\n"]}],"source":["print('BLEU Score: ',BLEU)\n","print('BERT Score: ',BERT)\n","print('Rouge-1 Score: ',Rouge_1)\n","print('Rouge-2 Score: ',Rouge_2)\n","print('Rouge-L Score: ',Rouge_L)\n","print('Redundancy Score: ',Redundancy)\n","BLEU_scores.append(BLEU)\n","BERT_scores.append(BERT)\n","Rouge_1_scores.append(Rouge_1)\n","Rouge_2_scores.append(Rouge_2)\n","Rouge_L_scores.append(Rouge_L)\n","Redundancy_scores.append(Redundancy)"]},{"cell_type":"markdown","metadata":{},"source":["## Topsis to find best model"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:48:38.066242Z","iopub.status.busy":"2024-02-04T07:48:38.065514Z","iopub.status.idle":"2024-02-04T07:48:38.086666Z","shell.execute_reply":"2024-02-04T07:48:38.083235Z","shell.execute_reply.started":"2024-02-04T07:48:38.066207Z"},"trusted":true},"outputs":[],"source":["models= ['facebook/bart-large-cnn','sshleifer/distilbart-cnn-12-6','philschmid/bart-large-cnn-samsum','google/pegasus-cnn_dailymail','knkarthick/MEETING_SUMMARY']"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:48:38.095370Z","iopub.status.busy":"2024-02-04T07:48:38.091666Z","iopub.status.idle":"2024-02-04T07:48:38.119563Z","shell.execute_reply":"2024-02-04T07:48:38.115872Z","shell.execute_reply.started":"2024-02-04T07:48:38.095213Z"},"trusted":true},"outputs":[],"source":["scores= [BLEU_scores,BERT_scores,Rouge_1_scores,Rouge_2_scores,Rouge_L_scores,Redundancy_scores]\n","for score in scores:\n","    for i in range(len(score)):\n","        score[i]= np.round(score[i],3)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:48:38.126954Z","iopub.status.busy":"2024-02-04T07:48:38.125648Z","iopub.status.idle":"2024-02-04T07:48:38.147857Z","shell.execute_reply":"2024-02-04T07:48:38.144708Z","shell.execute_reply.started":"2024-02-04T07:48:38.126806Z"},"trusted":true},"outputs":[],"source":["df_topsis= pd.DataFrame({\n","    'Model': models,\n","    'BLEU': BLEU_scores,\n","    'BERT': BERT_scores,\n","    'Rouge-1': Rouge_1_scores,\n","    'Rouge-2': Rouge_2_scores,\n","    'Rouge-L': Rouge_L_scores,\n","    'Redundancy': Redundancy_scores\n","})"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:48:38.153407Z","iopub.status.busy":"2024-02-04T07:48:38.152084Z","iopub.status.idle":"2024-02-04T07:48:38.166362Z","shell.execute_reply":"2024-02-04T07:48:38.163670Z","shell.execute_reply.started":"2024-02-04T07:48:38.153258Z"},"trusted":true},"outputs":[],"source":["weights= [1,1,1,1,1,1]             # assuming equal weights (you may choose weights according to your priorities)        \n","impacts= ['+','+','+','+','+','-']"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:48:38.171913Z","iopub.status.busy":"2024-02-04T07:48:38.171038Z","iopub.status.idle":"2024-02-04T07:48:38.201914Z","shell.execute_reply":"2024-02-04T07:48:38.199354Z","shell.execute_reply.started":"2024-02-04T07:48:38.171806Z"},"trusted":true},"outputs":[],"source":["def normalize(matrix):\n","    norm_matrix = matrix / np.sqrt(np.sum(matrix**2, axis=0))                    # normalize the matrix\n","    return norm_matrix\n","\n","def weighted_normalize(norm_matrix, weights):\n","    weighted_norm_matrix = norm_matrix * weights                                 # calculate the weighted normalized matrix\n","    return weighted_norm_matrix\n","\n","def ideal_best_worst(weighted_norm_matrix, impacts):\n","    ideal_solution = np.max(weighted_norm_matrix, axis=0) * impacts              # calculate the ideal_best and ideal_worst solutions\n","    ideal_worst_solution = np.min(weighted_norm_matrix, axis=0) * impacts\n","    return ideal_solution, ideal_worst_solution\n","\n","def euclidean_distances(weighted_norm_matrix, ideal_solution, ideal_worst_solution):\n","    dist_to_ideal = np.sqrt(np.sum((weighted_norm_matrix - ideal_solution)**2, axis=1))           # Calculate the Euclidean distances to the ideal_best and ideal_worst solutions.\n","    dist_to_ideal_worst = np.sqrt(np.sum((weighted_norm_matrix - ideal_worst_solution)**2, axis=1))\n","    return dist_to_ideal, dist_to_ideal_worst\n","\n","def performance_score(dist_to_ideal, dist_to_ideal_worst):\n","    score = dist_to_ideal_worst / (dist_to_ideal + dist_to_ideal_worst)            # calculate the topsis score for each model\n","    return score\n","\n","def topsis(matrix, weights, impacts):                                              # perform TOPSIS analysis\n","    # Step 1: Normalize the decision matrix\n","    norm_matrix = normalize(matrix)\n","    \n","    # Step 2: Calculate the weighted normalized decision matrix\n","    weighted_norm_matrix = weighted_normalize(norm_matrix, weights)\n","    \n","    # Step 3: Determine the ideal_best and ideal_worst solutions\n","    ideal_solution, ideal_worst_solution = ideal_best_worst(weighted_norm_matrix, impacts)\n","    \n","    # Step 4: Calculate the Euclidean distances to the ideal_best and ideal_worst solutions\n","    dist_to_ideal, dist_to_ideal_worst = euclidean_distances(weighted_norm_matrix, ideal_solution, ideal_worst_solution)\n","    \n","    # Step 5: Calculate the performance score for each alternative/model\n","    score = performance_score(dist_to_ideal, dist_to_ideal_worst)\n","    \n","    # Step 6: Rank the alternatives/models based on their performance scores\n","    sorted_indices = np.argsort(score)[::-1]                                       # Indices of scores sorted in descending order\n","    rankings = np.empty_like(sorted_indices)                                       # Create an empty array to store rankings\n","    rankings[sorted_indices] = np.arange(len(score)) + 1                           # Assign ranks\n","    \n","    return score, rankings"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:48:38.207423Z","iopub.status.busy":"2024-02-04T07:48:38.206182Z","iopub.status.idle":"2024-02-04T07:48:38.240203Z","shell.execute_reply":"2024-02-04T07:48:38.237595Z","shell.execute_reply.started":"2024-02-04T07:48:38.207238Z"},"trusted":true},"outputs":[],"source":["df_metrics= df_topsis.drop('Model',axis=1)\n","impacts_as_integers = [1 if impact == '+' else -1 for impact in impacts]"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:48:38.247075Z","iopub.status.busy":"2024-02-04T07:48:38.244974Z","iopub.status.idle":"2024-02-04T07:48:38.299506Z","shell.execute_reply":"2024-02-04T07:48:38.295836Z","shell.execute_reply.started":"2024-02-04T07:48:38.246837Z"},"trusted":true},"outputs":[],"source":["topsis_score, rankings = topsis(df_metrics, weights, impacts_as_integers)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:48:38.309178Z","iopub.status.busy":"2024-02-04T07:48:38.305068Z","iopub.status.idle":"2024-02-04T07:48:38.337647Z","shell.execute_reply":"2024-02-04T07:48:38.330571Z","shell.execute_reply.started":"2024-02-04T07:48:38.308907Z"},"trusted":true},"outputs":[],"source":["for i in range(len(topsis_score)):\n","    topsis_score[i] = np.round(topsis_score[i], 3)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:48:38.344706Z","iopub.status.busy":"2024-02-04T07:48:38.342574Z","iopub.status.idle":"2024-02-04T07:48:38.368633Z","shell.execute_reply":"2024-02-04T07:48:38.361900Z","shell.execute_reply.started":"2024-02-04T07:48:38.344577Z"},"trusted":true},"outputs":[],"source":["df_topsis['TOPSIS Score'] = topsis_score\n","df_topsis['TOPSIS Rank'] = rankings"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T07:48:38.379133Z","iopub.status.busy":"2024-02-04T07:48:38.375473Z","iopub.status.idle":"2024-02-04T07:48:38.443448Z","shell.execute_reply":"2024-02-04T07:48:38.438559Z","shell.execute_reply.started":"2024-02-04T07:48:38.379073Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>BLEU</th>\n","      <th>BERT</th>\n","      <th>Rouge-1</th>\n","      <th>Rouge-2</th>\n","      <th>Rouge-L</th>\n","      <th>Redundancy</th>\n","      <th>TOPSIS Score</th>\n","      <th>TOPSIS Rank</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>facebook/bart-large-cnn</td>\n","      <td>0.068</td>\n","      <td>0.878</td>\n","      <td>0.354</td>\n","      <td>0.117</td>\n","      <td>0.274</td>\n","      <td>0.537</td>\n","      <td>0.445</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sshleifer/distilbart-cnn-12-6</td>\n","      <td>0.049</td>\n","      <td>0.865</td>\n","      <td>0.311</td>\n","      <td>0.100</td>\n","      <td>0.244</td>\n","      <td>0.540</td>\n","      <td>0.430</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>philschmid/bart-large-cnn-samsum</td>\n","      <td>0.172</td>\n","      <td>0.921</td>\n","      <td>0.532</td>\n","      <td>0.292</td>\n","      <td>0.449</td>\n","      <td>0.559</td>\n","      <td>0.561</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>google/pegasus-cnn_dailymail</td>\n","      <td>0.051</td>\n","      <td>0.860</td>\n","      <td>0.319</td>\n","      <td>0.095</td>\n","      <td>0.254</td>\n","      <td>0.538</td>\n","      <td>0.431</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>knkarthick/MEETING_SUMMARY</td>\n","      <td>0.163</td>\n","      <td>0.917</td>\n","      <td>0.511</td>\n","      <td>0.274</td>\n","      <td>0.432</td>\n","      <td>0.560</td>\n","      <td>0.552</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              Model   BLEU   BERT  Rouge-1  Rouge-2  Rouge-L  \\\n","0           facebook/bart-large-cnn  0.068  0.878    0.354    0.117    0.274   \n","1     sshleifer/distilbart-cnn-12-6  0.049  0.865    0.311    0.100    0.244   \n","2  philschmid/bart-large-cnn-samsum  0.172  0.921    0.532    0.292    0.449   \n","3      google/pegasus-cnn_dailymail  0.051  0.860    0.319    0.095    0.254   \n","4        knkarthick/MEETING_SUMMARY  0.163  0.917    0.511    0.274    0.432   \n","\n","   Redundancy  TOPSIS Score  TOPSIS Rank  \n","0       0.537         0.445            3  \n","1       0.540         0.430            5  \n","2       0.559         0.561            1  \n","3       0.538         0.431            4  \n","4       0.560         0.552            2  "]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["df_topsis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
