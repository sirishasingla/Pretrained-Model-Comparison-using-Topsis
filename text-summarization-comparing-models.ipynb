{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-04T06:36:28.190424Z","iopub.execute_input":"2024-02-04T06:36:28.191229Z","iopub.status.idle":"2024-02-04T06:36:28.740491Z","shell.execute_reply.started":"2024-02-04T06:36:28.191165Z","shell.execute_reply":"2024-02-04T06:36:28.739369Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:36:28.743071Z","iopub.execute_input":"2024-02-04T06:36:28.744071Z","iopub.status.idle":"2024-02-04T06:36:29.442815Z","shell.execute_reply.started":"2024-02-04T06:36:28.744004Z","shell.execute_reply":"2024-02-04T06:36:29.441500Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install nltk rouge-score bert-score","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:36:29.444352Z","iopub.execute_input":"2024-02-04T06:36:29.444874Z","iopub.status.idle":"2024-02-04T06:36:45.161284Z","shell.execute_reply.started":"2024-02-04T06:36:29.444838Z","shell.execute_reply":"2024-02-04T06:36:45.159686Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: rouge-score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: bert-score in /opt/conda/lib/python3.10/site-packages (0.3.13)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.24.4)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.1.2+cpu)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.2.0)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.37.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.31.0)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.66.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.4)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert-score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert-score) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2023.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.20.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.15.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nfrom datasets import load_dataset\nfrom nltk.translate.bleu_score import corpus_bleu\nfrom rouge_score import rouge_scorer\nfrom bert_score import score","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:36:45.165801Z","iopub.execute_input":"2024-02-04T06:36:45.166356Z","iopub.status.idle":"2024-02-04T06:36:50.033810Z","shell.execute_reply.started":"2024-02-04T06:36:45.166303Z","shell.execute_reply":"2024-02-04T06:36:50.032390Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import warnings\n\n# Suppress the warning\nwarnings.filterwarnings(\"ignore\", message=\"Your max_length is set to *\")","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:36:50.035254Z","iopub.execute_input":"2024-02-04T06:36:50.035959Z","iopub.status.idle":"2024-02-04T06:36:50.042255Z","shell.execute_reply.started":"2024-02-04T06:36:50.035922Z","shell.execute_reply":"2024-02-04T06:36:50.040689Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Reading the Dataset","metadata":{}},{"cell_type":"code","source":"pip install py7zr","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:36:50.044191Z","iopub.execute_input":"2024-02-04T06:36:50.044714Z","iopub.status.idle":"2024-02-04T06:37:05.488248Z","shell.execute_reply.started":"2024-02-04T06:36:50.044673Z","shell.execute_reply":"2024-02-04T06:37:05.486515Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: py7zr in /opt/conda/lib/python3.10/site-packages (0.20.8)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\nRequirement already satisfied: pycryptodomex>=3.16.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (3.20.0)\nRequirement already satisfied: pyzstd>=0.15.9 in /opt/conda/lib/python3.10/site-packages (from py7zr) (0.15.9)\nRequirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.0)\nRequirement already satisfied: pybcj<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.0.2)\nRequirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from py7zr) (0.2.3)\nRequirement already satisfied: inflate64<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.0.0)\nRequirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = load_dataset(\"samsum\")","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:05.491828Z","iopub.execute_input":"2024-02-04T06:37:05.493072Z","iopub.status.idle":"2024-02-04T06:37:06.360596Z","shell.execute_reply.started":"2024-02-04T06:37:05.493020Z","shell.execute_reply":"2024-02-04T06:37:06.359567Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f87958dfc66c43f9853f11a3387a28d2"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:06.362177Z","iopub.execute_input":"2024-02-04T06:37:06.362800Z","iopub.status.idle":"2024-02-04T06:37:06.372737Z","shell.execute_reply.started":"2024-02-04T06:37:06.362768Z","shell.execute_reply":"2024-02-04T06:37:06.371227Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 14732\n    })\n    test: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 819\n    })\n    validation: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 818\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"df= dataset['test'].to_pandas()","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:06.374619Z","iopub.execute_input":"2024-02-04T06:37:06.374952Z","iopub.status.idle":"2024-02-04T06:37:06.395214Z","shell.execute_reply.started":"2024-02-04T06:37:06.374925Z","shell.execute_reply":"2024-02-04T06:37:06.394132Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df= df.sample(n= 150, replace= False).reset_index(drop= True)  ","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:06.399878Z","iopub.execute_input":"2024-02-04T06:37:06.400675Z","iopub.status.idle":"2024-02-04T06:37:06.408456Z","shell.execute_reply.started":"2024-02-04T06:37:06.400630Z","shell.execute_reply":"2024-02-04T06:37:06.407569Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Analysing the dataset","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:06.409702Z","iopub.execute_input":"2024-02-04T06:37:06.410573Z","iopub.status.idle":"2024-02-04T06:37:06.431295Z","shell.execute_reply.started":"2024-02-04T06:37:06.410539Z","shell.execute_reply":"2024-02-04T06:37:06.430299Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"         id                                           dialogue  \\\n0  13816051  Harriette: Have you ever gone ghost hunting? ;...   \n1  13681603  Ella: so? \\r\\nMolly: ?\\r\\nElla: come on! pics ...   \n2  13729101  Brenda: Hello, is this Sandra Donovan?\\r\\nSand...   \n3  13863098  Cristina: Hey\\nCristina: Do you think we can m...   \n4  13681441  Joanna: They are sending emails about Lewandow...   \n\n                                             summary  \n0  Jamie has never gone ghost hunting but Harriet...  \n1  Chuck told Ella that he'd met up with Molly. H...  \n2  Sandra and Brenda used to work together in the...  \n3  Gaya and Cristina are going to meet at Gaya's ...  \n4  Lewandowska has measles. There are vaccination...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dialogue</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13816051</td>\n      <td>Harriette: Have you ever gone ghost hunting? ;...</td>\n      <td>Jamie has never gone ghost hunting but Harriet...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13681603</td>\n      <td>Ella: so? \\r\\nMolly: ?\\r\\nElla: come on! pics ...</td>\n      <td>Chuck told Ella that he'd met up with Molly. H...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13729101</td>\n      <td>Brenda: Hello, is this Sandra Donovan?\\r\\nSand...</td>\n      <td>Sandra and Brenda used to work together in the...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13863098</td>\n      <td>Cristina: Hey\\nCristina: Do you think we can m...</td>\n      <td>Gaya and Cristina are going to meet at Gaya's ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13681441</td>\n      <td>Joanna: They are sending emails about Lewandow...</td>\n      <td>Lewandowska has measles. There are vaccination...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:06.432653Z","iopub.execute_input":"2024-02-04T06:37:06.433149Z","iopub.status.idle":"2024-02-04T06:37:06.445997Z","shell.execute_reply.started":"2024-02-04T06:37:06.433120Z","shell.execute_reply":"2024-02-04T06:37:06.444874Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 150 entries, 0 to 149\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   id        150 non-null    object\n 1   dialogue  150 non-null    object\n 2   summary   150 non-null    object\ndtypes: object(3)\nmemory usage: 3.6+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:06.447389Z","iopub.execute_input":"2024-02-04T06:37:06.448180Z","iopub.status.idle":"2024-02-04T06:37:06.466622Z","shell.execute_reply.started":"2024-02-04T06:37:06.448149Z","shell.execute_reply":"2024-02-04T06:37:06.465321Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"              id                                           dialogue  \\\ncount        150                                                150   \nunique       150                                                150   \ntop     13816051  Harriette: Have you ever gone ghost hunting? ;...   \nfreq           1                                                  1   \n\n                                                  summary  \ncount                                                 150  \nunique                                                150  \ntop     Jamie has never gone ghost hunting but Harriet...  \nfreq                                                    1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dialogue</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>13816051</td>\n      <td>Harriette: Have you ever gone ghost hunting? ;...</td>\n      <td>Jamie has never gone ghost hunting but Harriet...</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print('Dialogue:\\n',df['dialogue'][0])\nprint('\\nSummary:\\n',df['summary'][0])","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:06.468019Z","iopub.execute_input":"2024-02-04T06:37:06.468389Z","iopub.status.idle":"2024-02-04T06:37:06.474800Z","shell.execute_reply.started":"2024-02-04T06:37:06.468359Z","shell.execute_reply":"2024-02-04T06:37:06.473599Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Dialogue:\n Harriette: Have you ever gone ghost hunting? ;o\nJamie: Ghost hunting? Nah, not really... Have you?\nHarriette: Yeah, once when I was in high school! There was a run-down building in the neighbourhood and we went to investigate it with my friends\nJamie: How was it? Did you find something?\nHarriette: We didn't see any ghosts, haha\nHarriette: But let me tell you that I never thought I'd freak out this much at hearing a cat meow\nHarriette: There's just something about the atmosphere... that makes you overreact and find normal but unexpected things really creepy\nJamie: I guess that's part of the experience? :p\nHarriette: Yeah, if I could choose again, I'd probably still decide to go - I don't regret it! But I definitely wouldn't try something like that alone ^^;\n\nSummary:\n Jamie has never gone ghost hunting but Harriette did with her friends once in high school. They did not see any ghosts and she only got frightened by a cat's miaowing.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model Metric Evaluation","metadata":{}},{"cell_type":"code","source":"def calculate_redundancy(summaries):\n    \n    total_tokens = sum(len(summary.split()) for summary in summaries)\n    unique_tokens = len(set(token for summary in summaries for token in summary.split()))\n    redundancy_score = 1 - (unique_tokens / total_tokens)\n    \n    return redundancy_score","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:06.476646Z","iopub.execute_input":"2024-02-04T06:37:06.477422Z","iopub.status.idle":"2024-02-04T06:37:06.486856Z","shell.execute_reply.started":"2024-02-04T06:37:06.477368Z","shell.execute_reply":"2024-02-04T06:37:06.485632Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def calc_metrics(actual_summaries, pred_summaries):\n    \n    # Calculate BLEU Score\n    actual_summaries_tokenized = [[ref.split()] for ref in actual_summaries]         # tokenizing the actual summary\n    pred_summaries_tokenized = [output.split() for output in pred_summaries]         # tokenizing the predicted summary\n    bleu_score = corpus_bleu(actual_summaries_tokenized, pred_summaries_tokenized)   # comparing the tokens to calculate BLEU score\n    \n    \n    # Calculate BERT Score\n    P, R, F1 = score(actual_summaries, pred_summaries, lang='en', verbose=False)     # returns Precision, Recall and F1 score\n    bert_score = F1.mean().item()                                                    # takes the mean of F1 scores across all examples (.item() used to convert PyTorch tensor into scalar value) \n    \n    \n    # Calculate ROUGE Scores\n    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)          # creates an object 'rouge' that will be used to compute ROUGE scores with ROUGE-1, ROUGE-2, and ROUGE-L metrics, using stemming\n             \n    rouge_1_scores = []\n    rouge_2_scores = []\n    rouge_L_scores = []\n    for pred, actual in zip(pred_summaries, actual_summaries):\n        rouge_scores = rouge.score(pred, actual)                                                # returns a dictionary of mentioned ROUGE scores each of which contain precison, recall and F1 score\n        rouge_1_scores.append(rouge_scores['rouge1'].fmeasure)\n        rouge_2_scores.append(rouge_scores['rouge2'].fmeasure)\n        rouge_L_scores.append(rouge_scores['rougeL'].fmeasure)\n    \n    rouge_1_f1 = sum(rouge_1_scores) / len(rouge_1_scores)                                      # calculating the average rouge scores (considering F1 score)\n    rouge_2_f1 = sum(rouge_2_scores) / len(rouge_2_scores)\n    rouge_L_f1 = sum(rouge_L_scores) / len(rouge_L_scores)\n    \n    # Calculate Redundancy Score\n    redundancy_score = calculate_redundancy(pred_summaries)\n    \n    \n    return bleu_score, bert_score, rouge_1_f1, rouge_2_f1, rouge_L_f1, redundancy_score        # returning all the calculated metrics","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:06.488856Z","iopub.execute_input":"2024-02-04T06:37:06.489258Z","iopub.status.idle":"2024-02-04T06:37:06.505042Z","shell.execute_reply.started":"2024-02-04T06:37:06.489227Z","shell.execute_reply":"2024-02-04T06:37:06.503792Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Testing on different models","metadata":{}},{"cell_type":"markdown","source":"##### 1. facebook/bart-large-cnn","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nsummarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\nsummarizer(df['dialogue'][0], max_length= 130, min_length=30, truncation= True)   ","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:06.506585Z","iopub.execute_input":"2024-02-04T06:37:06.506997Z","iopub.status.idle":"2024-02-04T06:37:25.014001Z","shell.execute_reply.started":"2024-02-04T06:37:06.506967Z","shell.execute_reply":"2024-02-04T06:37:25.013085Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"2024-02-04 06:37:07.022931: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-04 06:37:07.023046: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-04 06:37:07.026859: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': \"Harriette went ghost hunting with her friends when she was in high school. They investigated a run-down building in the neighbourhood and didn't see any ghosts. Harriette says she doesn't regret going ghost hunting, but she wouldn't do it alone.\"}]"},"metadata":{}}]},{"cell_type":"code","source":"summarizer(df['dialogue'][0], max_length= 30, min_length=10, truncation= True)[0]['summary_text']","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:25.015467Z","iopub.execute_input":"2024-02-04T06:37:25.016825Z","iopub.status.idle":"2024-02-04T06:37:30.589411Z","shell.execute_reply.started":"2024-02-04T06:37:25.016788Z","shell.execute_reply":"2024-02-04T06:37:30.588180Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'Harriette went ghost hunting with her friends when she was in high school. They investigated a run-down building in the neighbourhood.'"},"metadata":{}}]},{"cell_type":"code","source":"predictions= []\nfor i in range(0,len(df)):\n    pred= summarizer(df['dialogue'][i], max_length=30, min_length=10, truncation= True)[0]['summary_text']\n    predictions.append(pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:37:30.590973Z","iopub.execute_input":"2024-02-04T06:37:30.591375Z","iopub.status.idle":"2024-02-04T06:49:49.889648Z","shell.execute_reply.started":"2024-02-04T06:37:30.591342Z","shell.execute_reply":"2024-02-04T06:49:49.888335Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Your max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\nYour max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\nYour max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\nYour max_length is set to 30, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\nYour max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","output_type":"stream"}]},{"cell_type":"code","source":"BLEU,BERT,Rouge_1,Rouge_2,Rouge_L,Redundancy = calc_metrics(df['summary'].tolist(), predictions)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:49:49.891405Z","iopub.execute_input":"2024-02-04T06:49:49.891750Z","iopub.status.idle":"2024-02-04T06:50:38.273898Z","shell.execute_reply.started":"2024-02-04T06:49:49.891722Z","shell.execute_reply":"2024-02-04T06:50:38.272547Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"BLEU_scores= []\nBERT_scores= []\nRouge_1_scores= []\nRouge_2_scores= []\nRouge_L_scores= []\nRedundancy_scores= []\nprint('BLEU Score: ',BLEU)\nprint('BERT Score: ',BERT)\nprint('Rouge-1 Score: ',Rouge_1)\nprint('Rouge-2 Score: ',Rouge_2)\nprint('Rouge-L Score: ',Rouge_L)\nprint('Redundancy Score: ',Redundancy)\nBLEU_scores.append(BLEU)\nBERT_scores.append(BERT)\nRouge_1_scores.append(Rouge_1)\nRouge_2_scores.append(Rouge_2)\nRouge_L_scores.append(Rouge_L)\nRedundancy_scores.append(Redundancy)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:50:38.275833Z","iopub.execute_input":"2024-02-04T06:50:38.276218Z","iopub.status.idle":"2024-02-04T06:50:38.285159Z","shell.execute_reply.started":"2024-02-04T06:50:38.276186Z","shell.execute_reply":"2024-02-04T06:50:38.283871Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"BLEU Score:  0.06819376766320177\nBERT Score:  0.8777881860733032\nRouge-1 Score:  0.3537191342343953\nRouge-2 Score:  0.11681459839731756\nRouge-L Score:  0.2743427144308629\nRedundancy Score:  0.5372358850017319\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 2. sshleifer/distilbart-cnn-12-6","metadata":{}},{"cell_type":"code","source":"pipe = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\npipe(df['dialogue'][0], max_length= 30, min_length=10, truncation= True)[0]['summary_text']       \n","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:50:38.287009Z","iopub.execute_input":"2024-02-04T06:50:38.287772Z","iopub.status.idle":"2024-02-04T06:50:52.937536Z","shell.execute_reply.started":"2024-02-04T06:50:38.287737Z","shell.execute_reply":"2024-02-04T06:50:52.936205Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf5c0061817149899698f55cfa67dfd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08f23945b17b491fa0d4b13246339de2"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75b9b61c4edd4674b1f916096e973739"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8fc1c6b2b4344f793834821fd925d34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"831eee86432241c989f0875a3101d2c8"}},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"' Harriette: Have you ever gone ghost hunting? ;o\\xa0\\xa0 Jamie: Ghost hunting? Nah, not really... Have you?'"},"metadata":{}}]},{"cell_type":"code","source":"predictions= []\nfor i in range(0,len(df)):\n    pred= pipe(df['dialogue'][i], max_length=30, min_length=10, truncation= True)[0]['summary_text']\n    predictions.append(pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:50:52.939380Z","iopub.execute_input":"2024-02-04T06:50:52.940186Z","iopub.status.idle":"2024-02-04T06:58:56.717640Z","shell.execute_reply.started":"2024-02-04T06:50:52.940135Z","shell.execute_reply":"2024-02-04T06:58:56.716192Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Your max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\nYour max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\nYour max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\nYour max_length is set to 30, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\nYour max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","output_type":"stream"}]},{"cell_type":"code","source":"BLEU,BERT,Rouge_1,Rouge_2,Rouge_L,Redundancy = calc_metrics(df['summary'].tolist(), predictions)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:58:56.719785Z","iopub.execute_input":"2024-02-04T06:58:56.720290Z","iopub.status.idle":"2024-02-04T06:59:45.383501Z","shell.execute_reply.started":"2024-02-04T06:58:56.720227Z","shell.execute_reply":"2024-02-04T06:59:45.382157Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"print('BLEU Score: ',BLEU)\nprint('BERT Score: ',BERT)\nprint('Rouge-1 Score: ',Rouge_1)\nprint('Rouge-2 Score: ',Rouge_2)\nprint('Rouge-L Score: ',Rouge_L)\nprint('Redundancy Score: ',Redundancy)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:59:45.386295Z","iopub.execute_input":"2024-02-04T06:59:45.387537Z","iopub.status.idle":"2024-02-04T06:59:45.395723Z","shell.execute_reply.started":"2024-02-04T06:59:45.387487Z","shell.execute_reply":"2024-02-04T06:59:45.394313Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"BLEU Score:  0.04917266108914351\nBERT Score:  0.8652205467224121\nRouge-1 Score:  0.31109114879000405\nRouge-2 Score:  0.09968754622698285\nRouge-L Score:  0.24437495396197187\nRedundancy Score:  0.539986559139785\n","output_type":"stream"}]},{"cell_type":"code","source":"BLEU_scores.append(BLEU)\nBERT_scores.append(BERT)\nRouge_1_scores.append(Rouge_1)\nRouge_2_scores.append(Rouge_2)\nRouge_L_scores.append(Rouge_L)\nRedundancy_scores.append(Redundancy)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:59:45.397285Z","iopub.execute_input":"2024-02-04T06:59:45.397726Z","iopub.status.idle":"2024-02-04T06:59:45.406871Z","shell.execute_reply.started":"2024-02-04T06:59:45.397693Z","shell.execute_reply":"2024-02-04T06:59:45.405852Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"#### 3. philschmid/bart-large-cnn-samsum","metadata":{}},{"cell_type":"code","source":"pipe = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")\nprint(pipe(df['dialogue'][0], max_length= 30, min_length=10, truncation= True)) \n","metadata":{"execution":{"iopub.status.busy":"2024-02-04T06:59:45.408195Z","iopub.execute_input":"2024-02-04T06:59:45.408633Z","iopub.status.idle":"2024-02-04T07:00:02.029332Z","shell.execute_reply.started":"2024-02-04T06:59:45.408602Z","shell.execute_reply":"2024-02-04T07:00:02.027991Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c69f7abb4d1142999f0af99e05967327"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c26668f70494d34a9ffe1335401f758"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/300 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"372ef2923c16420c859b668225a4356a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33d7153339c84f7ba2091a0a5fda1fbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91814a78991040d7b7594052becaea5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b70dfd8a121444b2a06c933094a6cc52"}},"metadata":{}},{"name":"stdout","text":"[{'summary_text': 'Harriette went ghost hunting once when she was in high school with her friends in a run-down building in the neighbourhood'}]\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions= []\nfor i in range(0,len(df)):\n    pred= pipe(df['dialogue'][i], max_length=30, min_length=10, truncation= True)[0]['summary_text']\n    predictions.append(pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:00:02.037398Z","iopub.execute_input":"2024-02-04T07:00:02.038232Z","iopub.status.idle":"2024-02-04T07:11:01.837570Z","shell.execute_reply.started":"2024-02-04T07:00:02.038191Z","shell.execute_reply":"2024-02-04T07:11:01.836297Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Your max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\nYour max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\nYour max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\nYour max_length is set to 30, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\nYour max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","output_type":"stream"}]},{"cell_type":"code","source":"BLEU,BERT,Rouge_1,Rouge_2,Rouge_L,Redundancy = calc_metrics(df['summary'].tolist(), predictions)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:11:01.839196Z","iopub.execute_input":"2024-02-04T07:11:01.839600Z","iopub.status.idle":"2024-02-04T07:11:47.369004Z","shell.execute_reply.started":"2024-02-04T07:11:01.839569Z","shell.execute_reply":"2024-02-04T07:11:47.366542Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"print('BLEU Score: ',BLEU)\nprint('BERT Score: ',BERT)\nprint('Rouge-1 Score: ',Rouge_1)\nprint('Rouge-2 Score: ',Rouge_2)\nprint('Rouge-L Score: ',Rouge_L)\nprint('Redundancy Score: ',Redundancy)\nBLEU_scores.append(BLEU)\nBERT_scores.append(BERT)\nRouge_1_scores.append(Rouge_1)\nRouge_2_scores.append(Rouge_2)\nRouge_L_scores.append(Rouge_L)\nRedundancy_scores.append(Redundancy)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:11:47.370882Z","iopub.execute_input":"2024-02-04T07:11:47.371323Z","iopub.status.idle":"2024-02-04T07:11:47.383484Z","shell.execute_reply.started":"2024-02-04T07:11:47.371291Z","shell.execute_reply":"2024-02-04T07:11:47.381988Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"BLEU Score:  0.1716887652393266\nBERT Score:  0.9205511212348938\nRouge-1 Score:  0.5321249492047778\nRouge-2 Score:  0.2916850985556861\nRouge-L Score:  0.44859674661969223\nRedundancy Score:  0.5589910496338486\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 4. google/pegasus-cnn_dailymail","metadata":{}},{"cell_type":"code","source":"pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\npipe(df['dialogue'][0], max_length= 30, min_length=10, truncation= True)[0]['summary_text'] ","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:11:47.385320Z","iopub.execute_input":"2024-02-04T07:11:47.385796Z","iopub.status.idle":"2024-02-04T07:12:41.463289Z","shell.execute_reply.started":"2024-02-04T07:11:47.385752Z","shell.execute_reply":"2024-02-04T07:12:41.462004Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c98ba65049c46009de0d9547ffa5cbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02640d127977479086d249cd40357138"}},"metadata":{}},{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"273a377b296540d7b84c46b02012d18a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36e0d1ce26d148e3bed4d250b3a76b88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13f5a63fc4064a7a9adc52df3aa49b9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4be493d86f9e482887a658ffabbaa211"}},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"\"Harriette went ghost hunting with her friends in high school .<n>She never thought she'd freak out at hearing a cat meow \""},"metadata":{}}]},{"cell_type":"code","source":"predictions= []\nfor i in range(0,len(df)):\n    pred= pipe(df['dialogue'][i], max_length=30, min_length=10, truncation= True)[0]['summary_text']\n    predictions.append(pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:12:41.465027Z","iopub.execute_input":"2024-02-04T07:12:41.465477Z","iopub.status.idle":"2024-02-04T07:34:06.451517Z","shell.execute_reply.started":"2024-02-04T07:12:41.465443Z","shell.execute_reply":"2024-02-04T07:34:06.450184Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Your max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\nYour max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\nYour max_length is set to 30, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\nYour max_length is set to 30, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\nYour max_length is set to 30, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\nYour max_length is set to 30, but your input_length is only 18. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\nYour max_length is set to 30, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\nYour max_length is set to 30, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n","output_type":"stream"}]},{"cell_type":"code","source":"BLEU,BERT,Rouge_1,Rouge_2,Rouge_L,Redundancy = calc_metrics(df['summary'].tolist(), predictions)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:34:06.453512Z","iopub.execute_input":"2024-02-04T07:34:06.454815Z","iopub.status.idle":"2024-02-04T07:34:59.116288Z","shell.execute_reply.started":"2024-02-04T07:34:06.454769Z","shell.execute_reply":"2024-02-04T07:34:59.114958Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"print('BLEU Score: ',BLEU)\nprint('BERT Score: ',BERT)\nprint('Rouge-1 Score: ',Rouge_1)\nprint('Rouge-2 Score: ',Rouge_2)\nprint('Rouge-L Score: ',Rouge_L)\nprint('Redundancy Score: ',Redundancy)\nBLEU_scores.append(BLEU)\nBERT_scores.append(BERT)\nRouge_1_scores.append(Rouge_1)\nRouge_2_scores.append(Rouge_2)\nRouge_L_scores.append(Rouge_L)\nRedundancy_scores.append(Redundancy)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:34:59.118229Z","iopub.execute_input":"2024-02-04T07:34:59.118707Z","iopub.status.idle":"2024-02-04T07:34:59.126506Z","shell.execute_reply.started":"2024-02-04T07:34:59.118663Z","shell.execute_reply":"2024-02-04T07:34:59.125336Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"BLEU Score:  0.050751401318902996\nBERT Score:  0.8598005175590515\nRouge-1 Score:  0.31919036232745535\nRouge-2 Score:  0.09517286377370723\nRouge-L Score:  0.2538947214047014\nRedundancy Score:  0.5382047477744807\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 5. knkarthick/MEETING_SUMMARY","metadata":{}},{"cell_type":"code","source":"pipe = pipeline(\"summarization\", model=\"knkarthick/MEETING_SUMMARY\")\npipe(df['dialogue'][0], max_length= 30, min_length=10, truncation= True)[0]['summary_text'] ","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:34:59.128505Z","iopub.execute_input":"2024-02-04T07:34:59.128954Z","iopub.status.idle":"2024-02-04T07:35:22.623954Z","shell.execute_reply.started":"2024-02-04T07:34:59.128913Z","shell.execute_reply":"2024-02-04T07:35:22.615039Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76ec8bfb20934c84a5711c972e873555"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23a07e7bb2ec4988998613559fcffd00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/337 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a30cf6fbb464c89b3fe754cb00c517d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6166bd406ea64a28babb061157b91515"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a3862379b3b407eb51c116f814689d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b39cdf057bf4407a86c2e53f373e6d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b59cb9cc0624ab3a6a609ac3435c0d5"}},"metadata":{}},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"\"Harriette went ghost hunting once when she was in high school. She didn't find any ghosts but she did find it\""},"metadata":{}}]},{"cell_type":"code","source":"predictions= []\nfor i in range(0,len(df)):\n    pred= pipe(df['dialogue'][i], max_length=30, min_length=10, truncation= True)[0]['summary_text']\n    predictions.append(pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:35:22.631305Z","iopub.execute_input":"2024-02-04T07:35:22.637049Z","iopub.status.idle":"2024-02-04T07:47:52.571816Z","shell.execute_reply.started":"2024-02-04T07:35:22.636813Z","shell.execute_reply":"2024-02-04T07:47:52.570642Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"Your max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\nYour max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\nYour max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\nYour max_length is set to 30, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\nYour max_length is set to 30, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","output_type":"stream"}]},{"cell_type":"code","source":"BLEU,BERT,Rouge_1,Rouge_2,Rouge_L,Redundancy = calc_metrics(df['summary'].tolist(), predictions)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:47:52.573762Z","iopub.execute_input":"2024-02-04T07:47:52.574112Z","iopub.status.idle":"2024-02-04T07:48:38.052839Z","shell.execute_reply.started":"2024-02-04T07:47:52.574083Z","shell.execute_reply":"2024-02-04T07:48:38.051354Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"print('BLEU Score: ',BLEU)\nprint('BERT Score: ',BERT)\nprint('Rouge-1 Score: ',Rouge_1)\nprint('Rouge-2 Score: ',Rouge_2)\nprint('Rouge-L Score: ',Rouge_L)\nprint('Redundancy Score: ',Redundancy)\nBLEU_scores.append(BLEU)\nBERT_scores.append(BERT)\nRouge_1_scores.append(Rouge_1)\nRouge_2_scores.append(Rouge_2)\nRouge_L_scores.append(Rouge_L)\nRedundancy_scores.append(Redundancy)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:48:38.054613Z","iopub.execute_input":"2024-02-04T07:48:38.055120Z","iopub.status.idle":"2024-02-04T07:48:38.063786Z","shell.execute_reply.started":"2024-02-04T07:48:38.055072Z","shell.execute_reply":"2024-02-04T07:48:38.062800Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"BLEU Score:  0.16257379211637224\nBERT Score:  0.9168060421943665\nRouge-1 Score:  0.5114647009961298\nRouge-2 Score:  0.2738689357642878\nRouge-L Score:  0.43198515492010814\nRedundancy Score:  0.5599679101484156\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Topsis to find best model","metadata":{}},{"cell_type":"code","source":"models= ['facebook/bart-large-cnn','sshleifer/distilbart-cnn-12-6','philschmid/bart-large-cnn-samsum','google/pegasus-cnn_dailymail','knkarthick/MEETING_SUMMARY']","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:48:38.065514Z","iopub.execute_input":"2024-02-04T07:48:38.066242Z","iopub.status.idle":"2024-02-04T07:48:38.086666Z","shell.execute_reply.started":"2024-02-04T07:48:38.066207Z","shell.execute_reply":"2024-02-04T07:48:38.083235Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"scores= [BLEU_scores,BERT_scores,Rouge_1_scores,Rouge_2_scores,Rouge_L_scores,Redundancy_scores]\nfor score in scores:\n    for i in range(len(score)):\n        score[i]= np.round(score[i],3)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:48:38.091666Z","iopub.execute_input":"2024-02-04T07:48:38.095370Z","iopub.status.idle":"2024-02-04T07:48:38.119563Z","shell.execute_reply.started":"2024-02-04T07:48:38.095213Z","shell.execute_reply":"2024-02-04T07:48:38.115872Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"df_topsis= pd.DataFrame({\n    'Model': models,\n    'BLEU': BLEU_scores,\n    'BERT': BERT_scores,\n    'Rouge-1': Rouge_1_scores,\n    'Rouge-2': Rouge_2_scores,\n    'Rouge-L': Rouge_L_scores,\n    'Redundancy': Redundancy_scores\n})","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:48:38.125648Z","iopub.execute_input":"2024-02-04T07:48:38.126954Z","iopub.status.idle":"2024-02-04T07:48:38.147857Z","shell.execute_reply.started":"2024-02-04T07:48:38.126806Z","shell.execute_reply":"2024-02-04T07:48:38.144708Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"weights= [1,1,1,1,1,1]             # assuming equal weights (you may choose weights according to your priorities)        \nimpacts= ['+','+','+','+','+','-']","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:48:38.152084Z","iopub.execute_input":"2024-02-04T07:48:38.153407Z","iopub.status.idle":"2024-02-04T07:48:38.166362Z","shell.execute_reply.started":"2024-02-04T07:48:38.153258Z","shell.execute_reply":"2024-02-04T07:48:38.163670Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def normalize(matrix):\n    norm_matrix = matrix / np.sqrt(np.sum(matrix**2, axis=0))                    # normalize the matrix\n    return norm_matrix\n\ndef weighted_normalize(norm_matrix, weights):\n    weighted_norm_matrix = norm_matrix * weights                                 # calculate the weighted normalized matrix\n    return weighted_norm_matrix\n\ndef ideal_best_worst(weighted_norm_matrix, impacts):\n    ideal_solution = np.max(weighted_norm_matrix, axis=0) * impacts              # calculate the ideal_best and ideal_worst solutions\n    ideal_worst_solution = np.min(weighted_norm_matrix, axis=0) * impacts\n    return ideal_solution, ideal_worst_solution\n\ndef euclidean_distances(weighted_norm_matrix, ideal_solution, ideal_worst_solution):\n    dist_to_ideal = np.sqrt(np.sum((weighted_norm_matrix - ideal_solution)**2, axis=1))           # Calculate the Euclidean distances to the ideal_best and ideal_worst solutions.\n    dist_to_ideal_worst = np.sqrt(np.sum((weighted_norm_matrix - ideal_worst_solution)**2, axis=1))\n    return dist_to_ideal, dist_to_ideal_worst\n\ndef performance_score(dist_to_ideal, dist_to_ideal_worst):\n    score = dist_to_ideal_worst / (dist_to_ideal + dist_to_ideal_worst)            # calculate the topsis score for each model\n    return score\n\ndef topsis(matrix, weights, impacts):                                              # perform TOPSIS analysis\n    # Step 1: Normalize the decision matrix\n    norm_matrix = normalize(matrix)\n    \n    # Step 2: Calculate the weighted normalized decision matrix\n    weighted_norm_matrix = weighted_normalize(norm_matrix, weights)\n    \n    # Step 3: Determine the ideal_best and ideal_worst solutions\n    ideal_solution, ideal_worst_solution = ideal_best_worst(weighted_norm_matrix, impacts)\n    \n    # Step 4: Calculate the Euclidean distances to the ideal_best and ideal_worst solutions\n    dist_to_ideal, dist_to_ideal_worst = euclidean_distances(weighted_norm_matrix, ideal_solution, ideal_worst_solution)\n    \n    # Step 5: Calculate the performance score for each alternative/model\n    score = performance_score(dist_to_ideal, dist_to_ideal_worst)\n    \n    # Step 6: Rank the alternatives/models based on their performance scores\n    sorted_indices = np.argsort(score)[::-1]                                       # Indices of scores sorted in descending order\n    rankings = np.empty_like(sorted_indices)                                       # Create an empty array to store rankings\n    rankings[sorted_indices] = np.arange(len(score)) + 1                           # Assign ranks\n    \n    return score, rankings","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:48:38.171038Z","iopub.execute_input":"2024-02-04T07:48:38.171913Z","iopub.status.idle":"2024-02-04T07:48:38.201914Z","shell.execute_reply.started":"2024-02-04T07:48:38.171806Z","shell.execute_reply":"2024-02-04T07:48:38.199354Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"df_metrics= df_topsis.drop('Model',axis=1)\nimpacts_as_integers = [1 if impact == '+' else -1 for impact in impacts]","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:48:38.206182Z","iopub.execute_input":"2024-02-04T07:48:38.207423Z","iopub.status.idle":"2024-02-04T07:48:38.240203Z","shell.execute_reply.started":"2024-02-04T07:48:38.207238Z","shell.execute_reply":"2024-02-04T07:48:38.237595Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"topsis_score, rankings = topsis(df_metrics, weights, impacts_as_integers)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:48:38.244974Z","iopub.execute_input":"2024-02-04T07:48:38.247075Z","iopub.status.idle":"2024-02-04T07:48:38.299506Z","shell.execute_reply.started":"2024-02-04T07:48:38.246837Z","shell.execute_reply":"2024-02-04T07:48:38.295836Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"for i in range(len(topsis_score)):\n    topsis_score[i] = np.round(topsis_score[i], 3)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:48:38.305068Z","iopub.execute_input":"2024-02-04T07:48:38.309178Z","iopub.status.idle":"2024-02-04T07:48:38.337647Z","shell.execute_reply.started":"2024-02-04T07:48:38.308907Z","shell.execute_reply":"2024-02-04T07:48:38.330571Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df_topsis['TOPSIS Score'] = topsis_score\ndf_topsis['TOPSIS Rank'] = rankings","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:48:38.342574Z","iopub.execute_input":"2024-02-04T07:48:38.344706Z","iopub.status.idle":"2024-02-04T07:48:38.368633Z","shell.execute_reply.started":"2024-02-04T07:48:38.344577Z","shell.execute_reply":"2024-02-04T07:48:38.361900Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"df_topsis","metadata":{"execution":{"iopub.status.busy":"2024-02-04T07:48:38.375473Z","iopub.execute_input":"2024-02-04T07:48:38.379133Z","iopub.status.idle":"2024-02-04T07:48:38.443448Z","shell.execute_reply.started":"2024-02-04T07:48:38.379073Z","shell.execute_reply":"2024-02-04T07:48:38.438559Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"                              Model   BLEU   BERT  Rouge-1  Rouge-2  Rouge-L  \\\n0           facebook/bart-large-cnn  0.068  0.878    0.354    0.117    0.274   \n1     sshleifer/distilbart-cnn-12-6  0.049  0.865    0.311    0.100    0.244   \n2  philschmid/bart-large-cnn-samsum  0.172  0.921    0.532    0.292    0.449   \n3      google/pegasus-cnn_dailymail  0.051  0.860    0.319    0.095    0.254   \n4        knkarthick/MEETING_SUMMARY  0.163  0.917    0.511    0.274    0.432   \n\n   Redundancy  TOPSIS Score  TOPSIS Rank  \n0       0.537         0.445            3  \n1       0.540         0.430            5  \n2       0.559         0.561            1  \n3       0.538         0.431            4  \n4       0.560         0.552            2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>BLEU</th>\n      <th>BERT</th>\n      <th>Rouge-1</th>\n      <th>Rouge-2</th>\n      <th>Rouge-L</th>\n      <th>Redundancy</th>\n      <th>TOPSIS Score</th>\n      <th>TOPSIS Rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>facebook/bart-large-cnn</td>\n      <td>0.068</td>\n      <td>0.878</td>\n      <td>0.354</td>\n      <td>0.117</td>\n      <td>0.274</td>\n      <td>0.537</td>\n      <td>0.445</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sshleifer/distilbart-cnn-12-6</td>\n      <td>0.049</td>\n      <td>0.865</td>\n      <td>0.311</td>\n      <td>0.100</td>\n      <td>0.244</td>\n      <td>0.540</td>\n      <td>0.430</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>philschmid/bart-large-cnn-samsum</td>\n      <td>0.172</td>\n      <td>0.921</td>\n      <td>0.532</td>\n      <td>0.292</td>\n      <td>0.449</td>\n      <td>0.559</td>\n      <td>0.561</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>google/pegasus-cnn_dailymail</td>\n      <td>0.051</td>\n      <td>0.860</td>\n      <td>0.319</td>\n      <td>0.095</td>\n      <td>0.254</td>\n      <td>0.538</td>\n      <td>0.431</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>knkarthick/MEETING_SUMMARY</td>\n      <td>0.163</td>\n      <td>0.917</td>\n      <td>0.511</td>\n      <td>0.274</td>\n      <td>0.432</td>\n      <td>0.560</td>\n      <td>0.552</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}